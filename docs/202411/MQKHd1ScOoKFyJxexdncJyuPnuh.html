<h1>AI 提示词（Prompt ）喂饭级系列教程 小白学习指南（一）（万字长文） </h1>
<blockquote>来源：<a href="https://eqsdsj0h4eo.feishu.cn/docx/MQKHd1ScOoKFyJxexdncJyuPnuh">https://eqsdsj0h4eo.feishu.cn/docx/MQKHd1ScOoKFyJxexdncJyuPnuh</a></blockquote>
<h1>一、基本概念｜Prompt 是什么？​</h1>

<p>在我们与 GPT 的互动中，"Prompt"是一个非常重要的概念。无论是在使用聊天机器人、进行创意写作，还是在其他 AI 应用中，了解什么是 Prompt 以及它如何工作，对于有效地使用 AI 技术至关重要。</p>

<h2>1、Prompt 的定义</h2>

<p>Prompt 是一种指令或信息，它引导或触发 AI 系统做出回应。在与 AI 如 ChatGPT 的交互中，每当我们输入一段文字，无论是问题、命令还是陈述，这段文字就是一个 Prompt。</p>

<p>想象 AI 是一位知识渊博的朋友，拥有广泛的信息和技能。当你与她对话时，你提出的每个问题或评论（即“Prompt”）都是对话的一部分。</p>

<p>比如，你可能会问她：“你对最近的科技发展有什么看法？”或者说：“请帮我概括一下太阳能的工作原理。”在这个情境中，每个问题或请求都是一个“Prompt”，引导你的朋友（AI）提供相关的信息、观点或执行特定的任务。</p>

<p>就像在与人的交谈中一样，你的“Prompt”的质量和清晰度将直接影响到对方的回应。清晰具体的问题会得到更精确和有用的答复。</p>

<p>如果你的问题模糊不清，你的朋友可能会需要更多的信息来提供有用的答案。同样，当你给 AI 一个清晰、明确的“Prompt”时，它可以更有效地理解你的请求并给出更准确的回应。</p>

<h2>2、Prompt 的作用</h2>

<ul><li>触发回应：Prompt 是与 AI 进行交流的起点，它告诉 AI 我们需要什么样的信息或反应。</li></ul>
<ul><li>引导对话：通过使用特定的 Prompt，我们可以引导 AI 沿着特定的思路或话题进行回答。</li></ul>
<ul><li>影响输出：AI 的回应会根据 Prompt 的内容而变化。一个明确、具体的 Prompt 通常会得到更精确和相关的回答。</li></ul>

<h2>3、Prompt 常用类型的使用示例</h2>

<ol><li>描述性 Prompt：</li></ol>
<ol><li>用途：用于描述或询问具体信息。</li></ol>
<ol><li>示例：“描述埃菲尔铁塔的历史。”</li></ol>

<p><img src="img/a5aeed8bd3973afd10135299b32216da.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/DUcqbtkZCoHBiIxJJNIcs3C7nub/"/></p>

<ol><li>创造性 Prompt：</li></ol>
<ol><li>用途：激发创新思维或产生新的想法。</li></ol>
<ol><li>示例：“创造一个关于未来城市的故事。”</li></ol>

<p><img src="img/566ad9033e6ce488a514b0f7bb61717a.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/I8U5bxb3EoXrf7xFPw6cska4n9d/"/></p>

<ol><li>指令性 Prompt：</li></ol>
<ol><li>用途：指导 AI 执行特定的任务或操作。</li></ol>
<ol><li>示例：“将这段文本翻译成法语。”</li></ol>

<p><img src="img/219586c0d7586810e5da4a06bc555118.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/VP1JbGU0xo5n5RxL0mncysMknkn/"/></p>

<ol><li>探索性 Prompt：</li></ol>
<ol><li>用途：用于探索或研究一个主题或问题。</li></ol>
<ol><li>示例：“探索全球变暖对极地生物的影响。”</li></ol>

<p><img src="img/0180023d1fc18163c6fdcbbe55826629.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Lqy1b2GHoo8vj0xqelfceqTqnkf/"/></p>

<ol><li>情感性 Prompt：</li></ol>
<ol><li>用途：探讨或表达情感、感受或心态。</li></ol>
<ol><li>示例：“写一首表达失落情感的诗。”</li></ol>

<p><img src="img/9d1a34aa8da69f262566ead7f54077b7.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Ejl0bZF7OoFPuvxmeRLceiRWnph/"/></p>

<ol><li>问题解答 Prompt：</li></ol>
<ol><li>用途：用来回答具体的问题或解决问题。</li></ol>
<ol><li>示例：“如果一个圆的半径是 5 米，那么它的面积是多少？”</li></ol>

<p><img src="img/15a6ef3563fc50919b49375294d93d38.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/SRuYbXLqpopEOtxmgv3cpCPhnEf/"/></p>

<p>新版本点击最右边，有执行分析步骤，很人性化：</p>

<p><img src="img/8f2c1cd9060acdb60dd0f224576f46cd.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Flx0bHFhpoGjaUxjlMxctWX8nIu/"/></p>

<ol><li>编程或代码 Prompt：</li></ol>
<ol><li>用途：用于编程任务或解决技术问题。</li></ol>
<ol><li>示例：“写一个 Python 脚本来排序一个数字列表。”</li></ol>

<p><img src="img/cd99ffec34aea114fc8e88d3a55144cb.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/XnazbZ5DFojR80xWheUclp9EnNf/"/></p>

<ol><li>咨询性 Prompt：</li></ol>
<ol><li>用途：在于提供分析、见解或建议。</li></ol>
<ol><li>示例：“给一位希望提高时间管理技能的专业人士提供建议。”</li></ol>

<p><img src="img/8e0e3709d9e100d7e43b6968a0e54f02.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/UQlUbDZxFowBXmxQKYncZYtznXf/"/></p>

<ol><li>图像生成 Prompt：</li></ol>
<ol><li>用途：用于创建或修改图像。</li></ol>
<ol><li>示例：“生成一幅描述太阳系的图像。”</li></ol>

<p><img src="img/665784cab595fdc5753029e818a59033.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/MeASbpQe9ouCp3xyUWFcQ19BnId/"/></p>

<ol><li>音频或视频 Prompt：</li></ol>
<ol><li>用途：用于生成或编辑音频和视频内容。</li></ol>
<ol><li>示例：“创建一个关于太阳系的短视频。”</li></ol>

<p>这类的目前 GPT 还无法实现此功能。但是已经有可以实现的了比如：Pika，Pixverse，以及现在特别火的 Sora 也是。</p>

<h1>二、基本概念｜Token 是什么？</h1>

<h2>1、引言</h2>

<p>在我们开始探索 GPT 的世界之前，让我们先来了解一下什么是“token”。这个概念对于理解 GPT 至关重要。</p>

<h2>2、什么是 Token？</h2>

<p>想象一下，你正在阅读一本书，但是这本书的每个字都是单独剪切出来的。在 GPT 的世界里，这些单独的字就像是“token”。</p>

<p>简单来说，token 是将文本分割成更小部分的一种方式。这些小部分可以是单个字、词或者短语。就像搭积木一样，GPT 通过这些 tokens 来理解和生成语言。</p>

<h2>3、Token 在 GPT 中的作用</h2>

<ol><li>理解语言：GPT 通过分析这些 tokens，就像孩子学习语言一样，逐渐理解单词的意义和如何将它们组合起来。</li></ol>
<ol><li>生成回复：当你向 GPT 提问时，它会将你的问题分解成 tokens，然后再组合新的 tokens 来构造回答。</li></ol>
<ol><li>提高效率：使用 tokens 可以让 GPT 更快地处理和理解大量的文本，就像通过拼图块快速构建图像一样。</li></ol>

<p><img src="img/3e063c417d0d4d9770a791c539907ea8.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/EQkFb0DBAokkrux6Av1cZwXEnCe/"/></p>

<p>GPT 实际是将我们输入的文字转换成 token，然后通过 GPT 模型预测需要输出的 token，最后再将 token 转换成文字，然后再输出给我们。</p>

<p>也就是说 GPT 只能理解 token，所以 GPT 会转化一下。</p>

<h2>4、Token 的类型</h2>

<p>在 GPT 中使用的 Token 类型与传统 自然语言处理 中的字级 Token 、词级 Token 和子词 Token 的概念有所不同（这里感谢小七姐的指正，之前我误以为 GPT 的 Token 是三种）。</p>

<p>GPT 使用基于 BPE 算法 的 Tokenization 方法，实际上较复杂，感兴趣的可以跳转：https://zhuanlan.zhihu.com/p/620426699</p>

<p>因为是入门的科普，这里进行简化理解，可以简单按照 自然语言处理 中的分类来理解（但实际上不是，这里大家一定要注意）：</p>

<ul><li>字级 Token：最小单位，例如中文中的每一个字。</li></ul>

<p><img src="img/6576f2576eeded53cd2adc47d38537df.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Q4hPby6jToDiBnxoeQPcDpIfnPn/"/></p>

<p>可以看到上面每一个汉字都是一个 Token。</p>

<ul><li>词级 Token：一些语言（如英语）中的单词。</li></ul>

<p><img src="img/3c8a1a2193d7b976e7a054dd782db0bf.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/PM6lb5RYFoMoOlxYwL9cRdQ6n2Y/"/></p>

<p>中国虽然是两个汉字，但是是一个 Token。</p>
<p><img src="img/9260ea504f8b08b42f11390a6ab679c5.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/NvNDbB2GGoUsI2xQVcUc2aQRn5p/"/></p>

<p>上面（ red）空格+red 四个字符算作一个 token</p>

<ul><li>子词 Token：把复杂的词分解成更简单的部分，这在处理不常见的词时特别有用。</li></ul>

<p><img src="img/a676b4b4865aa4069c2643170a15be06.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/QmHMbHoiCob2xsxapL0cww6nnNc/"/></p>

<p>上面虽然是两个汉字，但是拆解下来是 3 个 token，因为 “师” 被算为两个 token 的组合。</p>

<p><img src="img/312a77d50d960f571544c7017fd3c664.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/PbZ4b1iKqo0B58xM9vrc0D9knUe/"/></p>

<h2>5、实际应用</h2>

<p>那么 token 到底有什么用呢？我们为什么需要知道这些？</p>

<p>首先这里给大家一个 token 简单转化关系为：100 tokens ～= 75 单词 或者 ～= 100 个汉字。</p>

<h3>1）GPT tokens 是如何计算的？</h3>

<p>首先 OpenAI token 的计算包含两部分。用户输入给 GPT 模型的 token 数和 GPT 模型生成返回文本的 token 数。</p>

<p>例如，你提问耗费了 100 token（约 100 个汉字），GPT 根据你的输入，生成文本（也就是回答）了 200 token（约 200 个汉字），那么一共消费的 token 数就是 300 。</p>

<h3>2）GPT tokens 限制最大多少？</h3>

<p>首先看下 GPT-3.5 和 GPT-4.0 两个模型对应的支持最大的 tokens 数据：</p>
<p>官网地址：https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo</p>

<p><img src="img/daf26c6383b604901a82a5096fb67bfb.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/AcnlbCpb1o3btmxz7WNcZXsJnX2/"/></p>
<p><img src="img/311e7fd997954db530f310d59ec19c3a.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/CWbibm9Hqo9TyBxibphcODMSnyb/"/></p>

<p>GPT-3.5 的 token 的限制大约在 4096 左右，大约相当于 3072 个英文单词，或者 4096 左右个汉字 。</p>

<p>GPT-4 的 token 的限制大约在 8192 左右，大约相当于 6144 个英文单词，或者 8192 左右个汉字 。</p>

<h3>3）当超过最大 tokens 会怎么样？</h3>

<p>当对话的长度超过模型的最大 token 限制时，模型会开始"忘记"之前的对话内容。这是因为模型无法同时保留超过其最大 token 数量的信息。</p>

<p>在实践中，这意味着模型会丢弃较早的部分对话内容，以便为新的输入腾出空间。</p>

<p>例如，想象一个小孩子在听一个很长的故事。如果故事非常长，孩子可能会忘记故事开始时的内容。同样，当对话长度超过了模型的处理能力时，模型就会像孩子一样忘记对话的早期部分。</p>

<p>这种现象在长对话或复杂交互中尤其明显。因此，对话的管理和结构对于保持连贯性和相关性非常重要。</p>

<h3>4）如何查看我们使用了多少 token 呢？</h3>

<p>官网地址：https://platform.openai.com/tokenizer</p>

<p><img src="img/350650d0d9943b2cc350ae3851372589.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/PkWrbMwC1oxJ3IxrCcScbRqpnof/"/></p>

<p>上图文字我专门去除了英文，可以看出来，基本上是 1 比 1，我输入的有 331 个汉字，转换消耗 tokens 为 337 个 token。</p>

<p>再看下英文的情况：</p>

<p><img src="img/aabf460bf4b705126c7809d9b87b866e.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/JaNobwyXLoRehaxKHZqcmcNvnIh/"/></p>

<p>上图我大概输入了 700 个字母，算出来有 149 个 token，大约就是 4 个字母 ～= 一个 token。</p>

<h2>6、结论</h2>

<p>Token 限制对提示词编写有显著影响，特别是在长对话或连续多轮对话中。理解并考虑到 token 限制可以帮助有效地管理和构建对话，以下是一些具体的影响：</p>

<p>1. 有效记忆长度的把握：了解模型的 token 限制有助于预测和控制对话的有效记忆长度。这意味着在长对话中，你会意识到模型可能会忘记早期的交流内容。因此，避免在超过 token 限制时继续提问与最初的问题相关的内容，因为模型可能已经"忘记"了这些信息。</p>

<p>2. 简洁明了的表达：基于奥卡姆剃刀原理（即在解释事物时不应不必要地增加更多假设），建议在对话中使用简洁、直接的表达方式。这意味着避免冗长或不必要的话语，以减少 token 的消耗，并保持对话的清晰和焦点。</p>

<p>3. 重要信息的重复：在连续多轮对话中，如果某些信息非常重要，可以在不同时间点简要重复这些信息，以帮助模型保持对重要细节的记忆，特别是在长对话中。</p>

<p>4. 合理分段：在长文本或复杂问题的情况下，合理分段信息可以帮助模型更有效地处理和回应。这可以通过分解长问题或在长对话中定期总结已讨论的要点来实现。</p>

<h1>三、局限与困境｜ 时效性问题</h1>

<h2> 1、什么是 GPT 的时效性问题？</h2>

<p>GPT 是一个基于大量数据训练的 AI 模型。它通过分析过去的数据来生成回答，但是，这个模型不能实时更新，这意味着它的知识是停留在某个特定时间点的。</p>

<p><img src="img/909ad1de7a97efb9c9f0bc31ccafcdb6.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/MTWYb2pmKoxNslxieQxcKB59nhg/"/></p>

<p>通过询问 GPT 可以得知具体时间，那么 GPT 就不会 2023 年 4 月之后发生的事件。</p>

<p>所以当你问 GPT 一些关于最新新闻、流行文化或最近的科技发展的问题时，它无法提供最新的信息。它的回答可能基于过时的数据，这有时会导致误解或不准确的信息。</p>

<p>那我们怎么做呢？</p>

<ul><li>使用可以联网功能的 AI 工具：比如 GPT4 ，默认的对话框已经集成了最新上网功能，可以获取最新信息。</li></ul>

<p><img src="img/ffef92bb8a86dd87aa24cdbaf4b88a70.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/K2tebI8udo3Q0jx5Z6Kc7ka2nGg/"/></p>

<p>但是需要注意一点，就是这些信息，其实是通过内置的上网功能实时的获取数据，展示出来的而已。</p>

<p>这意味着什么呢？也就是说，GPT 训练库里面没有使用最新的数据进行训练。</p>

<p>我们来看看，GPT 是如何回答这个问题的：</p>

<p><img src="img/42fc129a718927529c78d5c5eb886264.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/CJBpbBNPxoIPWSx5XEmcycyfnuf/"/></p>

<p>那么我们最后再来看看，两种回复内容的本质区别：</p>

<p><img src="img/70dfc8e07032157774591bb5e3bd4fc4.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/MkulbNgwToktJAxkNpFc3l2lnHh/"/></p>

<p>所以，大家应该清楚了，时效性问题，到底会导致 GPT 回复的内容对我们的影响了吧。</p>

<h1>四、局限与困境｜ 幻觉问题</h1>

<h2>1、什么是幻觉问题？</h2>

<p>幻觉问题是指 GPT 在处理信息时可能产生的误解或错误。这种情况通常发生在 GPT 尝试理解复杂的概念、模棱两可的问题或非常新颖的话题时。</p>

<p>由于 GPT 是通过分析大量的文本数据训练出来的，它有时会“误解”这些数据或“过度推断”，从而产生不准确或虚构的回答。</p>

<p>定义：当模型生成的文本不遵循原文（Faithfulness）或者不符合事实（Factualness），我们就可以认为模型出现了幻觉的问题。</p>

<p>我们看下这个幻觉问题：</p>

<ul><li>输入冲突幻觉，GPT 生成的内容与事实不符。</li></ul>

<p><img src="img/0bb5c070232d2c656d8acf8d22ba6ea9.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/RYBBbQRphotL1BxGlP7cgwElnGh/"/></p>

<ul><li>语境冲突幻觉，GPT 生成的内容与之前生成的互相冲突：</li></ul>

<p><img src="img/30961a88f87ce47fc600a0bfd5f2ac42.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/KzgFbogD2o7qVvxaFKecQawinse/"/></p>

<ul><li>与事实相冲突的幻觉，GPT 成的信息或文本与已有的世界知识相矛盾：</li></ul>

<p><img src="img/f705000c9f0b5b74d03b93cd82d5e27c.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Z0YrbXsoIouHvYx9aWHcMOUVnng/"/></p>

<p><img src="img/8933cb589237ff74589cf385d8b0035c.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Rz3lbWh8JogoXZxOV4tcMjzBndg/"/></p>
<h2/>
<h2>2、幻觉的来源</h2>

<p>1）GPT 缺乏相关知识或内化错误知识</p>

<p>GPT 有时会将虚假的相关性（如位置接近或高度共现的关联）误解为事实知识，即 GPT 的幻觉与训练数据的分布之间存在很强的相关性。</p>

<p>2）GPT 有时会高估自己的能力</p>

<p>一些研究旨在了解语言模型是否能够评估其回答的准确性并识别其知识边界。然而，对于非常大的 GPT 来说，正确答案和错误答案的分布熵可能是相似的，这表明 GPT 在生成错误答案时与生成正确答案时同样自信。</p>

<p>3）有问题的对齐过程可能会产生幻觉</p>

<p>如果 GPT 在预训练阶段没有获得相关的先决知识，那么在训练指令时，这实际上是一个错误的对齐过程，会促使 GPT 产生幻觉。</p>

<p>另一个潜在问题是"谄媚"（sycophancy），即 GPT 可能会生成偏向用户观点的回答，而不是提供正确或真实的答案，这可能会导致幻觉</p>

<p>4）GPT 采用的生成策略存在潜在风险</p>

<p>但是，即使 GPT 意识到自己的早期错误是正确的，它们有时也会过度承诺。换句话说，GPT 可能更喜欢用“滚雪球”来实现自我一致性，而不是从错误中恢复。</p>

<h2>3、减少模型幻觉的实用技巧</h2>

<p>所以当我们向 GPT 询问某些问题时，它可能给出错误或虚构的答案。这些答案可能看起来合理，但实际上并不基于真实的事实或逻辑。这个问题尤其在处理非常专业或最新的话题时更加明显。</p>

<ol><li>提供清晰的上下文和约束条件</li></ol>

<ul><li>操作方法：在提示中提供足够的背景信息，并明确说明期望的范围或约束条件。让模型在特定范围内生成内容，有助于避免生成不符合逻辑或脱离主题的回答。</li></ul>

<ul><li>示例：在问医疗问题时，明确指出“仅基于最新的 2023 年医疗指南回答”或“不要进行未经证实的猜测”。</li></ul>

<ol><li>使用“逐步推理”的方法</li></ol>

<ul><li>操作方法：提示模型逐步推理出答案，而不是直接生成最终回答。这可以使模型更关注逻辑和细节，降低产生幻觉的概率。</li></ul>

<ul><li>示例：当讨论复杂问题时，可以引导模型先列出每个关键步骤或推理环节，以确保回答的严谨性。</li></ul>

<ol><li>引导模型“大声思考”</li></ol>

<ul><li>操作方法：让模型将其思考过程详细地表达出来，以便用户可以观察其推理路径。这样可以帮助识别任何不合理的假设，并纠正偏离的逻辑。</li></ul>

<ul><li>示例：问模型“在做出结论之前，请逐步列出你的推理过程，以便我确认你的逻辑路径。”</li></ul>

<ol><li>生成多个版本并挑选最佳答案</li></ol>

<ul><li>操作方法：提示模型生成多个不同的回答版本，然后综合这些答案或挑选最一致的那个。这种多角度分析可以减少模型对特定观点的偏倚，并提高准确性。</li></ul>

<ul><li>示例：询问“请提供三个不同角度的回答，然后我会根据这些回答综合出一个更准确的结论。”</li></ul>

<ol><li>指定信息来源或数据验证</li></ol>

<ul><li>操作方法：在提示中明确要求模型基于特定信息来源或数据集回答问题，或在回答中注明引用的来源。这样可以引导模型基于事实而非推测提供内容。</li></ul>

<ul><li>示例：在提出关于某个科学发现的问题时，要求“仅基于最近的科学文献进行回答”。</li></ul>

<ol><li>使用结构化 Prompt 和模板化格式</li></ol>

<ul><li>操作方法：采用结构化 Prompt（例如 CO-STAR 框架）来组织内容，明确回答的各个部分，让模型理解回答的结构并保持在任务的轨道上。</li></ul>

<ul><li>示例：在生成科技文章时，结构化提示可以包含“背景”、“关键要点”、“支持证据”等部分，确保回答保持清晰、逻辑性强。</li></ul>

<ol><li>设定回答长度限制</li></ol>

<ul><li>操作方法：限制回答的长度，避免模型提供过多的推测性内容。短而精确的回答通常更可靠，减少了模型生成无关或虚构信息的机会。</li></ul>

<ul><li>示例：在问一个简单的问题时，可以说明“请在 50 字以内回答，尽量简洁明了”。</li></ul>

<ol><li>指定模型使用可信的外部资源</li></ol>

<ul><li>操作方法：在涉及复杂或实时性强的问题时，要求模型引用权威资料或可信资源，如著名数据库或科学期刊。这有助于减少幻觉现象。</li></ul>

<ul><li>示例：在金融或健康类问题上，指明“请参考 X 机构的数据或指南”。</li></ul>

<ol><li>在复杂问题上重复询问并比较回答</li></ol>

<ul><li>操作方法：针对复杂问题，可以从不同的角度重新询问同一个问题，生成多个回答并进行比较，以识别并消除虚假或不一致的信息。</li></ul>

<ul><li>示例：对于历史事件的分析，重复提问并检查不同版本的回答是否一致，从而确保内容的准确性。</li></ul>

<ol><li>设定回答中的不准则或排除项</li></ol>

<ul><li>操作方法：在提示中列出特定的不准则或排除项，如“不允许基于未经证实的信息”“避免使用预测性语言”等。这可以有效减少模型的自由发挥空间，减少不准确内容的生成。</li></ul>

<ul><li>示例：在问财务建议时，可以说明“不使用未经证实的经济预测或市场猜测作为依据”。</li></ul>

<p>所以幻觉问题提醒我们，AI 并不完美，它的答案有时候需要进一步的核实和验证。使用 AI 时，保持警惕和批判性思维是非常重要的。</p>

<h1>五、 局限与困境｜记忆问题</h1>

<h2>1、什么是记忆问题？</h2>

<p>GPT 虽然能处理和生成复杂的文本，但它并不具备持久记忆的能力。这意味着它不能记住之前的对话内容或在不同会话之间保持信息的连贯性。这个问题其实我们在 tokens 章节就讲过的。</p>

<p>当对话的长度超过模型的最大 token 限制时，模型会开始"忘记"之前的对话内容。这是因为模型无法同时保留超过其最大 token 数量的信息。</p>

<p>在实践中，这意味着模型会丢弃较早的部分对话内容，以便为新的输入腾出空间。</p>

<p>这里给大家估算一下大致的长度：</p>

<p>GPT-3.5 ：当你发送的文字和 GPT 回复的文字大概 4000 个汉字或者 3000 个单词的时候，GPT 就可能忘记了你最开始的对话内容，按照一轮对话 500 - 1000 字的假设，也就是 4 - 8 个提问之后就可以再次发送 GPT 最开始设定的偏好或者个人信息了。</p>

<p>GPT-4：这个模型 大概是 8000 个汉字或者 6000 个单词，也就是 8 - 16 次对话之后就会失意了。</p>

<h2>2、这对我们意味着什么？</h2>

<p>这意味着在多轮对话后，它也不能记住你之前提供的个人信息或偏好设置。</p>

<h2>3、如何应对这个问题？</h2>

<p>1）有效记忆长度的把握：了解模型的 token 限制有助于预测和控制对话的有效记忆长度。这意味着在长对话中，你会意识到模型可能会忘记早期的交流内容。因此，避免在超过 token 限制时继续提问与最初的问题相关的内容，因为模型可能已经"忘记"了这些信息。</p>

<p>2）简洁明了的表达：基于奥卡姆剃刀原理（即在解释事物时不应不必要地增加更多假设），建议在对话中使用简洁、直接的表达方式。这意味着避免冗长或不必要的话语，以减少 token 的消耗，并保持对话的清晰和焦点。</p>

<p>3）重要信息的重复：在连续多轮对话中，如果某些信息非常重要，可以在不同时间点简要重复这些信息，以帮助模型保持对重要细节的记忆，特别是在长对话中。</p>

<p>4）合理分段：在长文本或复杂问题的情况下，合理分段信息可以帮助模型更有效地处理和回应。这可以通过分解长问题或在长对话中定期总结已讨论的要点来实现。</p>

<p>不过还有一个方法可以避免 GPT 的失忆问题，那就是自制 GPTs 把自己对 GPT 设置的个人信息和以及个人偏好封装起来，这样 GPT 就会一直记住你对她设定的数据。</p>
<p>接下来我们详细看下如何设置？</p>

<h2>4、GPT 4.0 自定义说明</h2>

<h3>1）点击进入自定义选项：</h3>
<h3/>
<p><img src="img/18e15db761e743f2f4b71dbbb2682f2e.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/BOiZbRVVloOxAWxM8LecczKGn0c/"/></p>

<h3>2）填写自定义内容</h3>

<p><img src="img/fc4b8f662c3db6cf83ce3512a0342eb2.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/WuskbyNpOo7MUxx2AwOc19S3nDg/"/></p>

<h4>1、第一个窗口中填写个人角色定位</h4>

<p>思维启发</p>

<p>你在哪个区域？</p>
<p>你的工作是什么？</p>
<p>你的爱好和兴趣是什么？</p>
<p>你可以聊什么话题聊上几个小时（兴趣）？</p>
<p>你有什么目标？</p>
<p><img src="img/a5199ab344937ac5e3ada68e7d7231f8.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/MoEXbM3b5oSbvUxEvIbcY3PfnPe/"/></p>

<h4>2、在第二个窗口中填写 GPT 输出标准</h4>

<p>思维启发</p>

<p>GPT 的语气应该正式还是轻松一些？</p>
<p>回复通常应该有多长或多短？</p>
<p>您希望我如何称呼您？</p>
<p>GPT 应该对某些话题有自己的观点还是保持中立？</p>

<p><img src="img/b55de25865dbac52de49536abb59ca09.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/FUkQbGMKAoeBiVxfy0Ic798Rnvd/"/></p>

<h2>5、GPT 的记忆功能</h2>

<p>当然最新的 GPT 还有一个记住你的功能，就是记忆功能，那如何使用 Memory 功能呢？在设置中点击“个性化（Personalization）”，然后进入“记忆（Memory）”设置。</p>

<p><img src="img/5a588ebce8dab337185c9e9647ca61cc.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/N8O2bEO0Tok7PZx2DSxcSxh0njf/"/></p>
<p><img src="img/241d8ad6a452056ce7f2caca9fccac00.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/CO88bGQfFo8ipkxLS9ic5J5Lnzd/"/></p>

<p>最初，Memory 是空的，不包含任何信息。更新记忆时，可以使用触发词如“请记住 XXX”或“我希望 XXX”。</p>

<p>更新后，如果看到“Memory updated”，则信息已被记下。回到“记忆（Memory）”设置，点击 Manage 查看所有记忆信息。如果信息有误，可以选择删除。</p>

<p>我们来看看测试结果：</p>

<p><img src="img/410aa70be80411924364318f00662094.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/XMCrbgYGzoYqqKxXpGScJugFnag/"/></p>

<p>那如何使用之前记忆的内容呢？</p>

<p><img src="img/4ef796aa1c1a383ab3a1453abd764d13.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/JJCeb9FvRoeLFBxab7ocnpLnnBd/"/></p>

<p>我们看到这个其实是可以起别名的呢，还是非常方便的。</p>

<p>那我们换一个新对话，看看能否记住呢？</p>
<p><img src="img/2f8c68a79e7ce38eab382b06bbcde35d.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Uyx7bGQOvotibYxuQ3QcL4xqnMA/"/></p>

<p>这里需要注意，在 GPTs 中无法调用这些记忆的内容。</p>

<p><img src="img/dff535323d4751ae4091e2b79cac2139.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/RmDsb7oklof5oIxMD2qcKxxYnNg/"/></p>

<p>我测试了这一功能，发现 GPT 现在可以根据记忆提供更个性化的回答。</p>

<p>我还测试了基于记忆的复杂推理，比如将优化文字的 Prompt 直接保存，以后就可以直接调用，避免重复输入。</p>

<p><img src="img/2d8611101d445663243b8c14d8ab40ff.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/DAWgbIP43o6O9UxuXGEcChHYnK7/"/></p>

<p>这对于一些简单的提示词，非常好用，不需要每次去搜索或者复制提示词，而搞一个 GPTs 反而会更加的笨重。</p>

<p>所以大家在使用 GPT 的时候，需要注意这个长度问题，就不会困惑为什么对话一段时间后，GPT 似乎忘记了什么？</p>

<h1>六、局限与困境｜韵脚问题</h1>

<h2>1、问题的定义</h2>

<p>韵脚问题是指 AI 在尝试创作押韵文本时所面临的困难，包括在保持意义、节奏和押韵的同时生成流畅和吸引人的内容。</p>

<p>尽管现代的 AI 模型如 GPT 在文本生成方面取得了显著进步，但在处理复杂的韵律结构时仍然存在挑战。</p>

<h2>2、问题的影响</h2>

<ul><li>押韵不自然：AI 生成的诗歌可能会在某些情况下使用不太自然的押韵。这是因为 AI 在尽量匹配给定的韵律结构时，可能会选择不完全合适的词语。人类诗人在创作时会考虑词语的意境和情感，而 AI 可能主要关注形式上的匹配，导致押韵显得生硬或牵强。</li></ul>

<ul><li>节奏不一致：古诗的节奏和韵律非常重要，但 AI 在创作时可能难以完全模拟出人类诗人的节奏感。古诗往往有严格的平仄规则和节奏要求，AI 可能会在保持这些规则的同时失去一些自然流畅的节奏。</li></ul>

<ul><li>内容牺牲：为了押韵或符合特定的韵律结构，AI 可能会牺牲内容的深度或丰富性。有时候，为了使句子押韵，AI 可能选择意义不够深刻或与上下文不完全吻合的词语，从而降低整体诗歌的艺术价值和表达深度。</li></ul>

<h2>3、如何解决？</h2>

<ul><li>具体指定韵律结构：如指定“ABAB”韵律模式或特定的诗歌形式。</li></ul>
<ul><li>提供样本或范例：给 AI 提供押韵文本的样本，以便模仿其风格和结构。</li></ul>
<ul><li>平衡内容与形式：在 prompt 中强调内容和韵律的平衡，以避免过分牺牲任一方面。</li></ul>

<p>来看下例子：</p>

<p><img src="img/1221747c5d349fa64739c36f90fca8d5.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/F25MbLFDioPPPpxng6rcj8dYnHf/"/></p>

<p>通过具体的指导、结合人工编辑以及不断的尝试和调整，我们可以利用 AI 来创作富有韵律和节奏的文学作品。</p>

<p>虽然 AI 可能无法完全替代人类在诗歌创作中的创造力和直觉，但它仍然是一个有价值的辅助工具。</p>

<h1>七、局限与困境｜精确字数问题</h1>

<h2>1、问题的定义</h2>

<p>精确字数问题指的是在使用文本生成 AI 时，难以精确控制生成文本的字数。这是因为 AI 模型如 GPT 在生成回复时，其主要目标是内容的相关性和准确性，而不是字数的精确控制。</p>

<h2>2、问题的影响</h2>

<ul><li>输出长度不可预测：AI 生成的文本长度可能不符合用户的具体需求，如过长或过短。</li></ul>
<ul><li>编辑和调整的需要：用户可能需要额外编辑 AI 的输出，以满足特定的字数要求。</li></ul>
<ul><li>困难在于满足格式要求：在有严格字数限制的格式中（如摘要、推文等），控制输出字数尤为重要。</li></ul>

<h2>3、怎么解决？</h2>

<ul><li>直接指定字数要求：例如，“写一个大约 100 字的简介”。</li></ul>

<p><img src="img/0925843b6f27f17ee696ba4b6bb24569.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/PWpabNVzto6XcPxklUdcqyVHn8b/"/></p>

<p>可以看到上面说了大约 100 字，但是还是给了快 200 字了😂。</p>

<p>来看下改进的方法的效果：</p>

<ul><li>使用结构化的请求：提供明确的结构要求，如“请提供三点建议，每点不超过 20 字”。</li></ul>

<p><img src="img/506db1b9e97617a83dcc26f855f3b602.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/MYaHbgaONoOusZxiQTQcuARKnLf/"/></p>

<ul><li>使用结构化的请求 2：请用简要描述环保的重要性，大概三句话，每句话 35 个字以内 </li></ul>

<p><img src="img/ca41c8731e816df4fc8b8982829854de.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/YN5abvZUdoBkv1xBvQScIYBynYg/"/></p>

<p>可以看到通过这个方法可以更好的控制文本字数。</p>

<ul><li>灵活调整期望：了解 AI 在字数控制上的局限，准备好进行必要的后期调整。</li></ul>

<p>所以大家理解这一局限性并学会相应地调整我们的使用方式，是提高 AI 工具使用效率的关键。</p>

<h1>八、局限与困境｜修辞机械问题</h1>

<h2>1、问题的定义</h2>

<p>修辞机械问题指的是 AI 生成的文本在修辞和表达上缺乏人类作家的那种流畅性、自然性和创造力。</p>

<p>虽然 AI，如 GPT，能够生成语法正确且逻辑连贯的文本，但这些文本有时可能显得过于刻板、缺乏情感色彩，或者在创意表达上不够丰富。</p>

<h2>2、问题的影响</h2>

<ol><li>文本缺乏吸引力：AI 生成的文本可能在某些情况下缺乏那种能够吸引和保持读者兴趣的修辞灵活性。这可能是因为 AI 在生成文本时，可能过于依赖常见的表达和句式，而缺乏那种能够引发读者情感共鸣或思考的独特视角或表达方式。</li></ol>

<ol><li>表达不够人性化：AI 生成的文本可能缺少人类作家那样的情感深度和个性化表达。人类作家能够在作品中融入自己的情感、经验和独特的世界观，这些是 AI 目前还难以完全复制的。因此，AI 生成的文本可能会给人一种表面上光鲜、但缺乏情感深度和个性化的感觉。</li></ol>

<ol><li>创意受限：虽然 AI 可以在特定框架内生成创造性的内容，但其在进行高度创造性工作，如诗歌、小说或特定风格的写作时，可能不如人类表现出色。AI 可能难以跳出其训练数据的范围，进行真正的创新或提出完全独特的观点。在需要个性化风格和新颖想法的写作任务中，AI 的表现可能不如预期。</li></ol>

<h2>3、怎么解决？</h2>

<ul><li>明确风格要求：在 prompt 中明确指出期望的写作风格，如“幽默”、“正式”或“抒情”。</li></ul>
<ul><li>提供示例或参考：给 AI 提供样本文本或风格参考，以便它能模仿特定的修辞风格。</li></ul>
<ul><li>分步骤请求：将写作任务分成多个步骤进行，逐步引导 AI 达到期望的修辞效果。</li></ul>

<p>我们来看下示例：</p>

<p><img src="img/50c5e479b0c4b7b3fe49a44390e35223.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/KxyIbMyVyoogUexcXaJcrlUnnDh/"/></p>

<p>通过明智地使用 AI，结合人类的创造力和编辑技巧，我们可以克服这一局限性，创造更丰富、更吸引人的内容。</p>

<h1>九、局限与困境｜约束失效问题</h1>

<h2>1、问题的定义</h2>

<p>约束失效问题发生在 AI 未能遵循或正确理解用户通过 prompts 设定的约束和限制。这可能包括忽视特定的指令、超出设定的话题范围，或在回应中包含不恰当的内容。</p>

<h2>2、问题的影响</h2>

<ul><li>输出超出预期范围：如果 AI 未能正确理解或遵循用户的指示，它可能生成与用户指定的范围或主题不符的内容。这不仅会导致用户得不到他们想要的结果，还可能产生不相关或不适当的内容。</li></ul>

<ul><li>违反指导原则：AI 系统通常需要遵循一定的道德和社会准则。如果 AI 在生成内容时无视了 prompt 中设定的道德或指导原则，可能会产生不道德、有偏见或不尊重人权的内容。</li></ul>

<ul><li>安全和合规性风险：约束失效在某些情况下可能会导致安全问题或违反特定的规范和法规。例如，如果 AI 生成的内容包含敏感信息、误导性信息或侵犯版权的材料，这可能会引起法律问题或信誉损失。</li></ul>

<h2>3、如何解决？</h2>

<ul><li>使用简洁的指令：避免过于复杂或模糊的指令，以减少解释上的歧义。</li></ul>

<p>原始 Prompt：“写一个故事，但是不要写得太长，也不要包含任何关于政治的内容，避免使用太专业的术语。”</p>

<p>优化后的 Prompt：“请写一个 200 字的非政治日常生活故事，避免使用专业术语。”</p>

<ul><li>设定明确的界限：在 prompt 中明确指出界限，或者不希望 AI 触及的话题或风格。</li></ul>

<p>原始 Prompt：“给我一些建议，但是不要让它们太复杂。”</p>

<p>优化后的 Prompt：“请给出三条简单的生活建议，每条不超过 15 字。”</p>

<ul><li>反复测试和调整：通过不断的实践和调整，找出最有效的方式来设定和传达约束。</li></ul>

<p>原始 Prompt（第一次尝试）：“描述一种未来的技术，但是不要太科幻。”</p>

<p>优化后的 Prompt（经过测试和调整后）：“请简述一种基于当前科技趋势的未来技术，200 字以内。”</p>

<p>其实主要看来例子，大家就会发现，最主要的能力还是你的文字表达能力，不要有歧义，还有就是需要较强的逻辑性。当你提高了这方面的能力，那么也就解决了 AI 的 约束失效的问题了。</p>

<p>那如何解决这些问题呢，大全再给大家一些常用的解决方法：</p>

<h1>一、实战技巧｜“大声思考”</h1>

<p>“大声思考”是一种通过口头表达内心思考过程的方法，以帮助更清晰地理解思维过程、检查逻辑、纠正错误或得出正确的答案。</p>

<p>这种方法在复杂任务中尤为重要，因为它可以引导模型逐步推理出答案，而不是立即得出最终答案。</p>

<h2>1、实现步骤</h2>

<p>具体来说，“大声思考”可以通过以下步骤实现：</p>

<ol><li>分解问题：将复杂问题分解为多个子问题或步骤，这样可以更容易地处理每个部分。</li></ol>
<ol><li>构建思维链：通过一系列有序、相互关联的思考步骤，模型能够更深入地理解问题，并生成结构化、逻辑清晰的回答。</li></ol>
<ol><li>逐步推理：在每一步骤中，模型需要进行逻辑推理，并将中间结果记录下来，以便后续步骤参考。</li></ol>
<ol><li>反馈与调整：根据初始回答调整提示，逐步引导模型提供更符合需求的答案。</li></ol>

<p>这种方法不仅提高了答案的可靠性，还增强了模型的可解释性和透明度。例如，在处理数学问题时，思维链提示比直接返回最终答案要差，直到模型大小达到一个临界值（如上百亿参数），之后模型的表现会好得多。</p>

<h2>2、示例</h2>

<p>这里给大家一个简单的示例：</p>

<p>Takeshi Kojima 等人在 2022 年发表的文章中，提示模型推理出答案的最简单方法是简单地在答案前加上 Let's think step by step。</p>

<p>下图给出了一个例子：</p>

<p><img src="img/7ba4a054aa9fd27b74db33d27e132a68.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/GCI1bZTjZoaER5xP7Ddc6mJZnog/"/></p>

<p>看下中文的效果：</p>

<p><img src="img/ae3729d06102b1a42ad78c16db616ea3.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/ODNubNhcuolBS5xGlwjcKCQtnPh/"/></p>

<p>结果：</p>

<p>将这个简单的技巧应用到 MultiArith 数学数据集上，作者发现，让我们一步一步地思考，准确率从 18%提高到 79%，翻了两番！</p>

<p><img src="img/1cf2793df5edf5f6404a4afb86ea43f7.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/IAoPbn3jgo3zc9xBjOicyDBHnMg/"/></p>

<p>影响：</p>

<p>尽管“让我们一步一步思考”的技巧在数学问题上很有效，但并不是对所有的任务都有效。作者发现它对多步算术问题、符号推理问题、策略问题和其他推理问题最有帮助。</p>

<p>它对简单的数学问题或常识性问题没有帮助，估计对许多其他非推理任务也没有帮助。</p>

<p><img src="img/d1e6b647658a037b7d3a225e46653fb3.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/QyFjbzip0oHj03xfOmdc9Uuen9d/"/></p>

<p>如果您将此技术应用于您自己的任务，请不要害怕尝试自定义指令。让我们考虑一步一步是相当通用的，因此您可能会发现使用遵循针对您的用例定制的更严格格式的指令会有更好的性能。</p>

<h2>3、复杂案例</h2>

<p>例如，您可以尝试更结构化的变体，例如，</p>
<p>首先，一步一步地思考为什么 X 可能是正确的。</p>
<p>其次，一步一步地思考为什么 Y 可能是正确的。</p>
<p>第三，一步一步地思考 X 和 Y 哪个更有意义。</p>
<p>你甚至可以给模型一个示例格式，以帮助保持它的轨道，例如：</p>

<pre>使用以下IRS指南，请按此格式回答以下问题：
（1）针对每个标准，判断车辆购买是否满足
- {标准} 让我们一步一步来。{解释} {是或否，如果问题不适用，则填N/A}。
（2）在逐个考虑每个标准后，将最终答案表述为：“因为{原因}，答案可能是{是或否}。”
IRS指南：
"""
如果您购买了符合以下标准的汽车或卡车，您可能有资格获得《第30D节》下的联邦税收抵免：
- 车辆是否有至少四个轮子？
- 车辆重量是否小于14,000磅？
- 车辆是否从至少4千瓦时的电池中获取能量，并且可以从外部来源充电？
- 车辆是否在2022年之前购买？
  - 如果是，制造商是否售出少于200,000辆符合条件的车辆？（特斯拉和通用汽车售出超过200,000辆符合条件的车辆。）
- 车辆是否在2022年之后购买？
  - 如果是，该车辆是否在以下北美组装车辆名单中？（在北美组装的唯一电动汽车包括：Audi Q5, BMW 330e, BMW X5, Chevrolet Bolt EUV, Chevrolet Bolt EV, Chrysler Pacifica PHEV, Ford Escape PHEV, Ford F系列, Ford Mustang MACH E, Ford Transit Van, GMC Hummer Pickup, GMC Hummer SUV, Jeep Grand Cherokee PHEV, Jeep Wrangler PHEV, Lincoln Aviator PHEV, Lincoln Corsair插电式, Lucid Air, Nissan Leaf, Rivian EDV, Rivian R1S, Rivian R1T, Tesla Model 3, Tesla Model S, Tesla Model X, Tesla Model Y, Volvo S60, BMW 330e, Bolt EV, Cadillac Lyriq, Mercedes EQS SUV，以及Nissan Leaf。)
"""
问题：我可以申请为2021年购买的丰田普锐斯普锐姆（Toyota Prius Prime）获得联邦税收抵免吗？
解决方案：
（1）针对每个标准，判断车辆购买是否满足
- 车辆是否有至少四个轮子？让我们一步一步来。丰田普锐斯普锐姆有四个轮子，所以答案是“是”。
- 车辆重量是否小于14,000磅？让我们一步一步来。丰田普锐斯普锐姆的重量小于14,000磅，所以答案是“是”。
- 车辆是否从至少4千瓦时的电池中获取能量，并且可以从外部来源充电？让我们一步一步来。丰田普锐斯普锐姆的电池容量满足这个要求，所以答案是“是”。
- 车辆是否在2022年之前购买？让我们一步一步来。丰田普锐斯普锐姆是在2021年购买的，所以答案是“是”。
- 车辆是否在2022年之后购买？不适用
- 如果是，该车辆是否在以下北美组装车辆名单中？不适用
（2）在逐个考虑每个标准后，最终答案表述为：“因为以下原因，答案可能是肯定的。”
因为丰田普锐斯普锐姆满足所有申请联邦税收抵免的标准，所以答案可能是“是”。</pre>

<p><img src="img/936b0aec45ae89e41401783b3a4aab24.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/VGdabtuzroaqUwxHM5qc37Lun4f/"/></p>

<h2>4、实际案例</h2>

<p>最后我们来简单看一个实际案例的效果：</p>

<p><img src="img/d456c19ff43e511acce851b4885297d0.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/UrARb4zvzoSBj1xMKeec22EhnMc/"/></p>

<p><img src="img/2768f49e70a5ce533d3ea88a4d01ab08.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/VYv5bmpZ1o5UryxM4rJcagxrnzg/"/></p>

<p>可以明显的看到第二次回答的其实更好一些，所有大家之后使用的时候，不妨都加上这么一句，而且据大全观察对于算数类型的，好一些的模型似乎都内置了这个提示词，就会导致差异没有那么明显了。</p>

<p>局限部分就到这里，下面是实战内容，有啥问题，也欢迎链接微信「daquan365」和我交流。</p>

<h1>二、实战技巧｜询问多种理由，综合答案</h1>

<h2>1、策略概述</h2>

<p>上节课，我们通过引导模型“逐步推理”和“大声思考”提高来回答的准确性和可靠性。</p>

<p>这一方法要求模型详细描述其推理过程，逐步解释每个步骤，而不是直接给出最终答案。这节课大全借助“多种理由”综合考虑的方式，模型可以更深入地分析问题，提供更全面和逻辑严密的答案。</p>

<h2>2、如何实践</h2>

<ol><li>要求模型详细描述推理过程：通过明确的指示，提示模型按照步骤逐步分析问题，并在每一步解释其思考过程。</li></ol>

<ol><li>鼓励模型“大声思考”：让模型表达其推理过程，描述它是如何从信息中得出结论的。这有助于发现潜在的错误或遗漏。</li></ol>

<ol><li>考虑多种可能性：提示模型在推理过程中探索多个可能的答案或观点，并对这些观点进行权衡和比较。</li></ol>

<ol><li>引导模型综合结论：在总结时，要求模型基于前面考虑的多种理由，给出一个全面且可靠的结论。</li></ol>

<h2>3、示例</h2>

<p>假设我们希望让模型分析“为什么远程办公在当今社会越来越受欢迎？”</p>

<h3>未使用“逐步推理”的简单提示</h3>

<p>“为什么远程办公在当今社会越来越受欢迎？”</p>

<p><img src="img/9abc09f57b7d8714aa5fc6f9599ccdbf.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Tqp3bFykHofTlbxO3DFc4YTXnqe/"/></p>

<p>可以看到 GPT 的回答比较分散而且非常的笼统。</p>

<p>那大全按照逐步推理，综合答案的方式写了一个提示词，我们再看看效果：</p>

<h3>使用“逐步推理”方法的 Prompt</h3>

<pre># Role: 综合理由可靠性推理者
## Profile
- Author: 大全
- Version: 1.0
- Language: 中文
- Description: 专注于通过询问多个理由并综合分析，以提高结论的可靠性。目标是确保在全面考虑多种可能性的基础上，提供最稳妥的答案。

## Background
你是一名具备深度分析和多角度思考能力的推理者，能够通过询问和评估多种理由，综合所有信息后得出可靠的结论。你的任务是最大程度地考虑所有相关因素，以确保最终结论的稳妥性和全面性。

## Goals
1. 综合分析多种可能性，并得出最可靠的结论。
2. 通过询问多种理由，确保考虑到所有潜在的因素和可能性。
3. 提供逻辑清晰且易于理解的推理过程，确保用户能够理解分析过程。
4. 对不同理由进行权衡和比较，确保得出的结论经过充分验证。
5. 确保结论在各种可能情境下都是稳妥且具有说服力的。

## Skills
1. 善于从多角度分析问题，询问并识别关键的理由和可能性。
2. 能够进行全面的逻辑推理，确保每一步分析都清晰可追踪。
3. 对不同的理由进行比较和权衡，找出最可靠的结论。
4. 在多种可能性中寻找联系并进行综合判断，确保结论的稳健性。
5. 保持语言简洁清晰，确保复杂的推理过程易于理解。

## Constrains
1. 必须对每个理由进行分析，不能忽略任何潜在的可能性。
2. 在推理过程中，避免过于依赖单一理由，确保综合考虑多种因素。
3. 确保每个推理步骤都有明确的依据，避免出现模糊或不确定的描述。
4. 尽可能提供多种情境的分析，确保结论的普适性和可靠性。
5. 避免冗长的描述，确保每个步骤都是关键且必要的。

## OutputFormat
1. 详细列出每个可能的理由，并对其进行分析。
2. 提供各个理由的优劣比较，明确指出每个理由的可信度和局限性。
3. 最终给出综合分析后的结论，并解释其背后的原因和依据。
4. 使用逻辑清晰的步骤，确保推理过程易于追踪。
5. 在总结部分，提供结论在不同情境下的适用性和可靠性分析。

## Workflows
1. **问题引导**：引导用户提出希望得到可靠答案的问题，明确分析目标。
2. **理由收集**：询问用户可能的理由或自行列出多个可能的理由，确保全面考虑。
3. **逐步分析**：对每个理由进行详细分析，描述其支持结论的依据和可能的不足之处。
4. **比较权衡**：对所有理由进行比较，找出最具说服力的理由，考虑各种可能性之间的关系。
5. **综合结论**：结合所有分析，提供最可靠的结论，并明确解释其背后的逻辑和依据。
6. **情境验证**：对结论在不同情境下的可靠性进行验证，确保结论的稳妥性和普适性。

## Initialization
以“请描述您希望我们详细分析并得出可靠结论的问题或情境。”为开场白，等待用户输入后，按照上述工作流程开始逐步推理。</pre>

<h3>使用该 Prompt 生成的结果</h3>

<p><img src="img/b691438563739413514cf38873aab70f.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/NhbDbERvtoC1BrxERL4c1pT9ncf/"/></p>

<h2>4、分析</h2>

<ul><li>逐步推理：模型没有直接给出答案，而是通过列举多个原因，逐一分析了每个原因的重要性和相关性。</li></ul>
<ul><li>多种可能性：模型考虑了技术进步、疫情影响、工作与生活平衡、企业成本等多个方面，确保答案全面。</li></ul>
<ul><li>综合结论：最终的结论涵盖了不同的观点，并清晰地解释了它们之间的关系和作用。</li></ul>

<h2>5、总结</h2>

<p>通过引导模型进行“逐步推理”和“大声思考”，可以显著提高复杂任务的可靠性。</p>

<p>让模型考虑多种可能性，并对每个观点进行权衡，能够确保生成的答案更全面、更严谨，避免遗漏重要信息。</p>

<p>这种方法对需要深度分析和多角度考虑的问题尤其有效。</p>

<p>今天的分享就到这里了，希望大家可以手动实操今天分享的内容，有任何问题欢迎交流。</p>